{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1. Basic Text Pre-processing\n",
    "#### Name: Matthew Bentham\n",
    "\n",
    "\n",
    "Date: 02/10/2022\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas\n",
    "* re\n",
    "* numpy\n",
    "* nltk \n",
    "* intertools\n",
    "* os\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The objective of this task is to perform basic text pre-processing on 776 job descriptions so that the words and language used in the description of each job can be easily assigned meaning. After successful completion of this process this more simplified and less noisy version of the description section of each job text file can then be used to generate document vectors to be inputted in an NLP machine learning model for the purpose of text classification. \n",
    "\n",
    "**Pre-processing tasks:**   \n",
    "1. Tokenisation & case uniformity \n",
    "2. Removal of short words (<2)\n",
    "3. Removal of stopwords \n",
    "4. Removal of less frequent words and most frequent words\n",
    "\n",
    "\n",
    "**INPUTS**:\n",
    "- 4 X folders with the job category being the folder name, containing the job description of each job under that category\n",
    "- Categories:\n",
    "    * Accounting Finance \n",
    "    * Engineering \n",
    "    * Healthcare Nursing \n",
    "    * Sales\n",
    "- Each job.txt contains:\n",
    "    * Title \n",
    "    * Web index value (unique)\n",
    "    * Company \n",
    "    * Description \n",
    "\n",
    "**OUTPUTS**:\n",
    "- **Jobs.txt**: Contains all job decscriptions in a single file (line per description)\n",
    "- **Vocab.txt**: Contains the unigram vocabulary, in the format *word_string:word_integer_index*\n",
    "- **webindxs.txt**: Contains a list of all the stored web index values in the same order as the job.txt file \n",
    "- **jobtitles.txt**:Contains a list of all the titles in the same order as the job.txt file \n",
    "- **jobtypes.txt**:Contains a list of all the job types in the same order as the job.txt file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries\n",
    "import nltk\n",
    "from nltk.probability import *\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 loading data\n",
    "*NOTE: format of the data folders can be seen in the intro above*  \n",
    "\n",
    "**TASKS**\n",
    "- Load the data into proper data structures and get it ready for processing.\n",
    "- Extract webIndex and description into proper data structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "# Directories used:\n",
    "dir_ = \"data/\"\n",
    "paths =['Accounting_Finance','Engineering','Healthcare_Nursing','Sales']\n",
    "# Initialise lists to store description , job_indx , job titles , job_type\n",
    "job_descriptions = [] \n",
    "job_indxs = []\n",
    "job_titles = []\n",
    "job_type=[]\n",
    "company = []\n",
    "\n",
    "# Iterate through each directory and extract the requred information using regex \n",
    "\n",
    "for type1 in paths:\n",
    "    \n",
    "    dir_path = dir_+type1\n",
    "    for filename1 in sorted(os.listdir(dir_path)): # we want to load articles in ascending order of their file names\n",
    "        if filename1.endswith(\".txt\"): # we only look at the txt file\n",
    "            file = dir_path+\"/\"+filename1 # this gives the file path\n",
    "            \n",
    "            with open(file,\"r\",encoding= 'unicode_escape') as f:\n",
    "                lines = f.readlines()\n",
    "                count=0\n",
    "                company_count = 0\n",
    "                for line in lines:\n",
    "                    index=re.search(r'Webindex: (\\d+)',line) \n",
    "                    title = re.search(r'Title: (.+)\\n$',line)\n",
    "                    Description = re.search(r'Description: (?:[a-zA-Z]+(?:\\s[a-zA-Z]+)?: )?(.+)',line)\n",
    "                    Company = re.search(r'Company: (.+)\\n$',line)\n",
    "                    \n",
    "                    if title:\n",
    "                        job_titles.append(title.group(1))\n",
    "                    if index:\n",
    "                        job_indxs.append(index.group(1))\n",
    "                    if Company:\n",
    "                        company_count = 1\n",
    "                        company.append(Company.group(1))\n",
    "                    if Description:\n",
    "                        job_descriptions.append(str(Description.group(1)))\n",
    "                if company_count == 0:\n",
    "                    company.append('NA')\n",
    "                job_type.append(type1)\n",
    "                \n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Web indexs</th>\n",
       "      <th>Catergory</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68802053</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>FP&amp;A  Blue Chip</td>\n",
       "      <td>Hays Senior Finance</td>\n",
       "      <td>A market leading retail business is going thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70757636</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Part time Management Accountant</td>\n",
       "      <td>FS2 UK Ltd</td>\n",
       "      <td>You will be responsible for the efficient runn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71356489</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>IFA  EMPLOYED</td>\n",
       "      <td>Clark James Ltd</td>\n",
       "      <td>Role The purpose of the role is to provide adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69073629</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Finance Manager</td>\n",
       "      <td>Accountancy Action Ltd</td>\n",
       "      <td>Excellent opportunity to join our client, an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70656648</td>\n",
       "      <td>Accounting_Finance</td>\n",
       "      <td>Management Accountant</td>\n",
       "      <td>Alexander Lloyd</td>\n",
       "      <td>Our client offers a interesting opportunity fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Web indexs           Catergory                            Title  \\\n",
       "0   68802053  Accounting_Finance                  FP&A  Blue Chip   \n",
       "1   70757636  Accounting_Finance  Part time Management Accountant   \n",
       "2   71356489  Accounting_Finance                    IFA  EMPLOYED   \n",
       "3   69073629  Accounting_Finance                  Finance Manager   \n",
       "4   70656648  Accounting_Finance            Management Accountant   \n",
       "\n",
       "                  Company                                        Description  \n",
       "0     Hays Senior Finance  A market leading retail business is going thro...  \n",
       "1              FS2 UK Ltd  You will be responsible for the efficient runn...  \n",
       "2         Clark James Ltd  Role The purpose of the role is to provide adv...  \n",
       "3  Accountancy Action Ltd  Excellent opportunity to join our client, an e...  \n",
       "4         Alexander Lloyd  Our client offers a interesting opportunity fo...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data={'Web indexs':job_indxs,'Catergory':job_type,'Title':job_titles,'Company':company,'Description':job_descriptions}\n",
    "data=pd.DataFrame(data=data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Job files: 776\n"
     ]
    }
   ],
   "source": [
    "print('Number of Job files:',len(job_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing data\n",
    "\n",
    "After doing some preliminary analysis of the raw data it can be seen that there is some formatting errors when the advertisements were converted to txt files. These include:\n",
    "- `brbr` scattered throughout the files (HTML formatting)\n",
    "- Additional subheadings after `Description:` (e.g. Position: , Job description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Staff Nurse  RGN will also consider Newly Qualified brLocation: Selby brSalary: **** per hour plus overtime rate brbrJob Description: brI am currently looking to recruit a qualified RGN to work for a service based within a rural location. The service is CQC compliant and part of a Yorkshire based Healthcare Company brbrJob Requirements:brbrResponsible for the assessment of care/support needs of service usersbrDevelopment and implementation of care programmes brWorking alongside other nurses reporting to the Manager brSkills/ Qualifications:brbrRegistered Nurse  RGN will also consider newly qualified brDesire to make a difference to people brPassionate at delivering services that enhance lives brBenefits:brSalary **** per hour plus overtime rate brHoliday entitlement brEXCELLENT career progression and training opportunities brPicturesque working environment brFor more information on how to apply for this fantastic opportunity please contact Shona Blackburn on or email a copy of your up to date CV for immediate attention to'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "job_descriptions[488]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see subheadings likes `brBenefits:brSalary` or `Skills/ Qualifications:` dont actually give any intrinsic information about job itself and therefore can be removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,a in enumerate(job_descriptions):\n",
    "\n",
    "    # Remove all invalid br values from job_description list\n",
    "    check = re.compile(r'(?:(br)+([A-Z]))')\n",
    "    check =re.sub(check,r'\\2',a)\n",
    "    job_descriptions[i]=check\n",
    "\n",
    "    # remove all subheadings from job_description list\n",
    "    check2= re.findall(r'[A-Z]\\w+:',check)\n",
    "    if check2:\n",
    "        fixed_des =re.sub(r'[A-Z]\\w+:','',check)\n",
    "        job_descriptions[i]=fixed_des\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Tokenization & case uniformity \n",
    "Each word in the job description needs to be tokenized. The word tokenization must uses the following regular expression: r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\" which accounts for words with - and ' symbols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_txt(txt):\n",
    "    \"\"\"\n",
    "        This function tokenizes a raw text document.\n",
    "    \"\"\"        \n",
    "    txt_lower = txt.lower() # cover all words to lowercase\n",
    "\n",
    "    pattern = r'''(?x)          \n",
    "    [a-zA-Z]+(?:[-'][a-zA-Z]+)?       #Regex expression extracts all words including those with - & ' embedded \n",
    "    '''\n",
    "    tokenizer = nltk.RegexpTokenizer(pattern) \n",
    "    tokenised_text = tokenizer.tokenize(txt_lower)\n",
    "    return tokenised_text\n",
    "\n",
    "tokenised_job_descriptions = [tokenize_txt(job) for job in job_descriptions]  # list comprehension, generate a list of tokenized articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Remove small words \n",
    "Remove words with length less than 2. This ensures indefinite articles like `a` or pronouns like `i` do not take up space in the job tokenised as they give no indication towards job type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Removed words:\n",
      "----------------------------------------\n",
      "[['a', 'a', 'a', 'a', 'a', 't'], ['a', 'a', 'a'], ['a', 'a', 'a'], ['a'], ['a', 'a', 'a', 'a', 'i', 't', 'a', 'a', 'a', 'k'], ['a', 'a', 'a', 'a', 'a'], ['a'], ['a', 'i', 'a', 'a', 'a', 'a'], ['a', 'a', 'a', 'a', 'p', 'l', 'a', 'a', 'a', 's'], ['a']]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "removed_words = [[w for w in job if len(w)<2] \\\n",
    "                      for job in tokenised_job_descriptions]\n",
    "tokenised_job_descriptions = [[w for w in job if len(w)>=2] \\\n",
    "                      for job in tokenised_job_descriptions]\n",
    "print('-'*40)\n",
    "print('Removed words:')\n",
    "print('-'*40)\n",
    "print(removed_words[0:10])\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above single letters like 'a' were removed from the list of tokens as they hold no significance as to the job type thier reside in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Remove stop words\n",
    "Stopwords are removed using the provided stop words list (stopwords_en.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of stop words \n",
    "stopwords_ = []\n",
    "with open('./stopwords_en.txt') as f:\n",
    "    stopwords_ = f.read().splitlines()\n",
    "\n",
    "\n",
    "# filter out stop words located in tokenised_job_descriptions\n",
    "\n",
    "no_stops =[]\n",
    "for job in tokenised_job_descriptions:\n",
    "    no_stop = []\n",
    "    for w in job:\n",
    "        if w not in stopwords_:\n",
    "            no_stop.append(w)\n",
    "            \n",
    "    no_stops.append(no_stop)\n",
    "tokenised_job_descriptions = no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Stopwords:\n",
      "----------------------------------------\n",
      "['a', \"a's\", 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', \"c'mon\", \"c's\", 'came', 'can', \"can't\", 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*40)\n",
    "print('Stopwords:')\n",
    "print('-'*40)\n",
    "print(stopwords_[0:100])\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords as seen above were removed from the token lists as they generally contain low-level information and generally take away focus from the more important class specific words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Remove Less and Most frequent words \n",
    "- Remove the word that appears only once in the document collection (term frequency =1).\n",
    "- Remove the top 50 most frequent words by the number of documents they appear in (document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VOCAB\n",
    "words = list(chain.from_iterable(tokenised_job_descriptions))# we put all the tokens in the corpus in a single list\n",
    "vocab = set(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Term frequencies:\n",
      "----------------------------------------\n",
      "[('slow', 1), ('applytodaystarttomorrownewsalesfor', 1), ('envolve', 1), ('ue', 1), ('organically', 1), ('complemented', 1), ('wwf', 1), ('amnesty', 1), ('bundles', 1), ('invaluable', 1), ('waiter', 1), ('bartender', 1), ('altringham', 1), ('bolton', 1), ('rochdale', 1), ('helens', 1), ('embarking', 1), ('faint', 1), ('hearted', 1), ('recruitmentsalesexecutive', 1), ('appealing', 1), ('ordered', 1), ('stuck', 1), ('salesadministrator', 1), ('titlebusiness', 1), ('industryinternational', 1), ('parcel', 1), ('surpass', 1), ('businessdevelopmentmanagercourierservices', 1), ('koteuncapp', 1), ('redirects', 1), ('solves', 1), ('educate', 1), ('browse', 1), ('infrastructures', 1), ('developmentongoing', 1), ('atmospherea', 1), ('qualityrewarded', 1), ('generously', 1), ('struggling', 1), ('openended', 1), ('towcester', 1), ('resultsfocussed', 1), ('percentage', 1), ('mentors', 1), ('monetary', 1), ('biotechnology', 1), ('rod', 1), ('plowe', 1), ('rp', 1), ('lcwallacehind', 1), ('recruitmentconsultantsearchselect', 1), ('warwickshire', 1), ('pabx', 1), ('cti', 1), ('voip', 1), (\"pc's\", 1), ('stat', 1), ('smartlist', 1), (\"ireland's\", 1), ('newspapers', 1), ('magazines', 1), ('dealmonster', 1), ('jobstoday', 1), ('wellloved', 1), ('titles', 1), ('fixedprice', 1), ('oubound', 1), ('lively', 1), ('potentials', 1), ('aiming', 1), ('preempt', 1), ('misdescriptions', 1), ('hackney', 1), ('islington', 1), ('clerkenwell', 1)]\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Less frequent words:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'whois',\n",
       " 'inpatient',\n",
       " 'assertiveness',\n",
       " 'stone',\n",
       " 'londoncare',\n",
       " 'facilitation',\n",
       " \"cv's\",\n",
       " 'dealt',\n",
       " 'validity',\n",
       " 'sapa',\n",
       " 'shelf',\n",
       " 'agendas',\n",
       " 'allowancepensionhealthcare',\n",
       " 'bromsgrove',\n",
       " 'multicultural',\n",
       " 'kgv',\n",
       " 'trollies',\n",
       " 'gatekeeper',\n",
       " 'interrogate',\n",
       " 'remaining',\n",
       " 'pest',\n",
       " 'deferred',\n",
       " 'btec',\n",
       " 'yellow',\n",
       " 'bamber',\n",
       " 'mainting',\n",
       " 'therapies',\n",
       " 'newspapers',\n",
       " 'ampm',\n",
       " 'processor',\n",
       " 'allround',\n",
       " 'mode',\n",
       " 'teller',\n",
       " 'greeks',\n",
       " 'retrieve',\n",
       " 'amplitude',\n",
       " 'woods',\n",
       " 'sjh',\n",
       " 'rigorous',\n",
       " 'offenders',\n",
       " 'takeoffs',\n",
       " 'mdm',\n",
       " 'washington',\n",
       " 'implication',\n",
       " 'vulnerability',\n",
       " 'timeframes',\n",
       " 'kpmg',\n",
       " 'eurolondon',\n",
       " 'geo',\n",
       " 'yearly',\n",
       " 'dominates',\n",
       " 'werkshage',\n",
       " 'academia',\n",
       " 'implicitly',\n",
       " 'slots',\n",
       " 'portsdown',\n",
       " 'citations',\n",
       " 'hazan',\n",
       " 'hurt',\n",
       " 'classleading',\n",
       " 'thunderhclplc',\n",
       " 'opportunties',\n",
       " 'corporates',\n",
       " 'acs',\n",
       " 'churchdown',\n",
       " 'socialwork',\n",
       " 'spending',\n",
       " 'cousins',\n",
       " 'mortgageprocessor',\n",
       " 'alliance',\n",
       " 'supportability',\n",
       " 'label',\n",
       " 'chose',\n",
       " 'stamping',\n",
       " 'attains',\n",
       " 'testandvalidationengineer',\n",
       " 'buick',\n",
       " 'intentionally',\n",
       " 'safehands',\n",
       " 'alot',\n",
       " 'churchill',\n",
       " 'deprivation',\n",
       " 'fieldsalesengineersoutherncentralscotland',\n",
       " 'btelesalestraineesgladlyaccepted',\n",
       " 'ocs',\n",
       " 'sixth',\n",
       " 'def',\n",
       " 'electronicengineer',\n",
       " 'acci',\n",
       " 'sabre',\n",
       " 'ota',\n",
       " 'wilmslow',\n",
       " 'parental',\n",
       " 'ajc',\n",
       " 'reacting',\n",
       " 'connect',\n",
       " 'finniganpopulusconsultants',\n",
       " 'polices',\n",
       " 'dunfermline',\n",
       " 'consideredadditional',\n",
       " 'broadbased',\n",
       " 'embraces',\n",
       " 'toulouse',\n",
       " 'afraid',\n",
       " 'dracup',\n",
       " 'ntms',\n",
       " 'burelf',\n",
       " 'porduction',\n",
       " 'modem',\n",
       " 'electrochemistry',\n",
       " 'enjoyment',\n",
       " 'commercialaccountant',\n",
       " 'barnt',\n",
       " 'recruitmentrevolution',\n",
       " 'farnborough',\n",
       " 'respectful',\n",
       " 'irregularity',\n",
       " 'ashe',\n",
       " 'toil',\n",
       " 'guinness',\n",
       " 'frs',\n",
       " 'spends',\n",
       " 'waiting',\n",
       " 'ceisiadau',\n",
       " 'blow',\n",
       " 'articulated',\n",
       " 'entitlements',\n",
       " 'buttress',\n",
       " 'gyms',\n",
       " 'lucky',\n",
       " 'retreat',\n",
       " 'culminating',\n",
       " 'defeat',\n",
       " 'apparel',\n",
       " 'othersthis',\n",
       " 'formula',\n",
       " 'remits',\n",
       " 'gauge',\n",
       " 'umms',\n",
       " 'microcephaly',\n",
       " 'substantiation',\n",
       " 'inhibit',\n",
       " 'alloys',\n",
       " 'rabaiotti',\n",
       " 'kilfoyleselectiongroup',\n",
       " 'president',\n",
       " 'introducers',\n",
       " 'extreme',\n",
       " 'dressings',\n",
       " 'widen',\n",
       " 'bereaved',\n",
       " 'salesexecinternal',\n",
       " 'informative',\n",
       " 'prejudice',\n",
       " 'caused',\n",
       " \"pc's\",\n",
       " 'linq',\n",
       " 'rated',\n",
       " 'borrows',\n",
       " 'keith',\n",
       " 'stripping',\n",
       " 'ntier',\n",
       " 'xst',\n",
       " 'usage',\n",
       " 'negligible',\n",
       " 'painting',\n",
       " 'disrepute',\n",
       " 'fats',\n",
       " 'mpayment',\n",
       " 'ncm',\n",
       " 'jw',\n",
       " 'worldleading',\n",
       " 'intravenous',\n",
       " 'personalities',\n",
       " 'optimize',\n",
       " 'senioreducationrecruitmentconsultantbirmingham',\n",
       " 'deliveries',\n",
       " 'romsey',\n",
       " 'highspec',\n",
       " 'raglenni',\n",
       " 'experiencegood',\n",
       " 'detoxification',\n",
       " 'timekeeping',\n",
       " 'campaigning',\n",
       " 'replying',\n",
       " 'comcats',\n",
       " 'imaginative',\n",
       " 'eradicate',\n",
       " 'caledonian',\n",
       " 'victims',\n",
       " 'disruption',\n",
       " 'angle',\n",
       " 'heat',\n",
       " 'awconsultingltd',\n",
       " 'threepeople',\n",
       " 'throsolwg',\n",
       " 'articulately',\n",
       " 'translational',\n",
       " 'parhaus',\n",
       " 'buzzard',\n",
       " 'telecomm',\n",
       " 'vrv',\n",
       " 'managements',\n",
       " 'august',\n",
       " 'rydym',\n",
       " 'hasn',\n",
       " 'extraordinary',\n",
       " 'recognises',\n",
       " 'fcus',\n",
       " 'ise',\n",
       " 'financebusinesspartner',\n",
       " 'explorer',\n",
       " 'incircuit',\n",
       " 'hilton',\n",
       " 'sewage',\n",
       " 'eba',\n",
       " 'cashflows',\n",
       " 'holidaysbms',\n",
       " 'internalsalesaccountmanager',\n",
       " 'wilson',\n",
       " 'orientatedinterested',\n",
       " 'seniorleadengineer',\n",
       " 'leaver',\n",
       " 'ohand',\n",
       " 'map',\n",
       " 'laminar',\n",
       " 'testability',\n",
       " 'aspires',\n",
       " 'privilege',\n",
       " 'earth',\n",
       " 'harman',\n",
       " 'faxes',\n",
       " 'worthington',\n",
       " 'despatch',\n",
       " 'ht',\n",
       " 'scade',\n",
       " 'cramlington',\n",
       " 'cook',\n",
       " 'grip',\n",
       " 'aftercare',\n",
       " 'salesrepresentativeconstructiontraineeorexperiencedconsidered',\n",
       " 'thoracic',\n",
       " 'likeable',\n",
       " 'pathways',\n",
       " 'compulsory',\n",
       " 'binding',\n",
       " 'msc',\n",
       " 'neat',\n",
       " 'progresses',\n",
       " 'precompletion',\n",
       " 'logbooks',\n",
       " 'gilchrist',\n",
       " 'tradition',\n",
       " 'shortfall',\n",
       " 'tt',\n",
       " 'proses',\n",
       " 'barrowinfurness',\n",
       " 'immaculate',\n",
       " 'judge',\n",
       " 'journalists',\n",
       " 'unethical',\n",
       " 'remunerated',\n",
       " 'matthews',\n",
       " 'streams',\n",
       " 'regulator',\n",
       " 'outstandings',\n",
       " 'fod',\n",
       " 'corfforaethol',\n",
       " 'monmouth',\n",
       " 'openigs',\n",
       " 'curious',\n",
       " 'furnishings',\n",
       " 'destamat',\n",
       " 'handbookd',\n",
       " 'finalising',\n",
       " 'ferrous',\n",
       " 'pontefract',\n",
       " 'expressed',\n",
       " 'postcloses',\n",
       " 'confidentially',\n",
       " 'forget',\n",
       " 'nurture',\n",
       " 'stats',\n",
       " 'receives',\n",
       " 'determines',\n",
       " 'exclusivity',\n",
       " 'prescreen',\n",
       " 'gathered',\n",
       " 'digitaltestengineer',\n",
       " 'nmcresponsible',\n",
       " 'captured',\n",
       " 'ntd',\n",
       " 'lloydspharmacy',\n",
       " 'gains',\n",
       " 'grows',\n",
       " 'riskanalyst',\n",
       " 'brownfield',\n",
       " 'publicly',\n",
       " 'meredith',\n",
       " 'ryanh',\n",
       " 'nteract',\n",
       " 'peterlee',\n",
       " 'iwerddon',\n",
       " 'perfformiad',\n",
       " 'apprentices',\n",
       " 'thrust',\n",
       " 'recklessly',\n",
       " 'observe',\n",
       " 'ocassional',\n",
       " 'ii',\n",
       " 'financeassistant',\n",
       " 'benchmark',\n",
       " 'servicesaround',\n",
       " 'reverse',\n",
       " 'carenecessary',\n",
       " 'graduatesalesengineer',\n",
       " 'closeknit',\n",
       " 'acrobat',\n",
       " 'subordinates',\n",
       " 'scripts',\n",
       " 'vested',\n",
       " 'pieces',\n",
       " 'unquestionably',\n",
       " 'recruitmentnhslothian',\n",
       " 'lengthy',\n",
       " 'interdisciplinary',\n",
       " 'creates',\n",
       " 'achieves',\n",
       " 'cfd',\n",
       " 'parcel',\n",
       " 'eventempered',\n",
       " 'sensor',\n",
       " 'modularizing',\n",
       " 'injured',\n",
       " 'realisation',\n",
       " 'rrp',\n",
       " 'hightech',\n",
       " 'excellentorganisation',\n",
       " 'pretender',\n",
       " 'berkhamsted',\n",
       " 'cbt',\n",
       " 'autistic',\n",
       " 'blurays',\n",
       " 'downloading',\n",
       " 'fullyfuelled',\n",
       " 'unconscious',\n",
       " 'whorelishes',\n",
       " 'unplanned',\n",
       " \"europe's\",\n",
       " 'checkweighers',\n",
       " 'scores',\n",
       " 'academics',\n",
       " 'lunsars',\n",
       " 'benefitsour',\n",
       " 'franchised',\n",
       " 'stimulate',\n",
       " 'poultry',\n",
       " 'confront',\n",
       " 'warranties',\n",
       " 'readily',\n",
       " 'realisable',\n",
       " 'sighted',\n",
       " 'indispensable',\n",
       " 'gaines',\n",
       " 'tray',\n",
       " 'overachieving',\n",
       " 'martin',\n",
       " 'nonmedical',\n",
       " 'pe',\n",
       " 'intentions',\n",
       " 'wifi',\n",
       " 'testers',\n",
       " 'dmrb',\n",
       " 'kay',\n",
       " 'capacities',\n",
       " 'recuse',\n",
       " 'chillers',\n",
       " 'pallets',\n",
       " 'donnington',\n",
       " 'prm',\n",
       " 'boasted',\n",
       " 'designates',\n",
       " 'enforcement',\n",
       " 'bannerappointgroup',\n",
       " 'picture',\n",
       " 'telco',\n",
       " 'aah',\n",
       " 'condo',\n",
       " 'workflows',\n",
       " 'motability',\n",
       " 'struggling',\n",
       " 'groupcontrolsanalyst',\n",
       " 'query',\n",
       " 'clientside',\n",
       " 'accessories',\n",
       " 'careerswedbush',\n",
       " 'threats',\n",
       " 'frankfurt',\n",
       " 'immigration',\n",
       " 'requesting',\n",
       " 'wishing',\n",
       " 'amrec',\n",
       " \"homeware's\",\n",
       " 'crest',\n",
       " 'demonstrator',\n",
       " 'pressurized',\n",
       " 'abstracts',\n",
       " 'personcentred',\n",
       " 'partaking',\n",
       " 'hyder',\n",
       " 'switched',\n",
       " 'banner',\n",
       " 'oq',\n",
       " 'arising',\n",
       " 'directorate',\n",
       " 'adverse',\n",
       " 'ol',\n",
       " 'instances',\n",
       " 'barnet',\n",
       " 'reimburse',\n",
       " 'possession',\n",
       " 'goruchwylio',\n",
       " 'seafield',\n",
       " 'datacentre',\n",
       " 'interpretations',\n",
       " 'atleast',\n",
       " 'jasonaddtec',\n",
       " 'navigation',\n",
       " 'amtech',\n",
       " 'subassemblies',\n",
       " \"aelodau'r\",\n",
       " 'aviation',\n",
       " 'suspicious',\n",
       " 'dixon',\n",
       " 'nele',\n",
       " 'coshh',\n",
       " 'spam',\n",
       " 'neonatal',\n",
       " 'hatstand',\n",
       " 'carter',\n",
       " 'multiindustry',\n",
       " 'geosciences',\n",
       " 'peaks',\n",
       " 'responsibliities',\n",
       " 'complicated',\n",
       " 'seniorbrokerslondon',\n",
       " 'prohibited',\n",
       " 'attendant',\n",
       " 'behavior',\n",
       " 'stw',\n",
       " 'strategol',\n",
       " 'ulcers',\n",
       " 'ra',\n",
       " 'dear',\n",
       " \"crb's\",\n",
       " 'mitigation',\n",
       " 'renovations',\n",
       " 'constructors',\n",
       " 'ho',\n",
       " 'howarthregionalrecruitment',\n",
       " 'leighton',\n",
       " 'tenaciousyou',\n",
       " 'roberts',\n",
       " 'burning',\n",
       " 'winners',\n",
       " 'likes',\n",
       " 'tonometers',\n",
       " 'memberships',\n",
       " 'distinctive',\n",
       " 'cf',\n",
       " 'megh',\n",
       " 'successdriven',\n",
       " 'uphold',\n",
       " 'entailing',\n",
       " 'crack',\n",
       " 'attentive',\n",
       " 'tdracupaktonrecruitment',\n",
       " 'aneesha',\n",
       " 'rig',\n",
       " 'areasalesrepresentative',\n",
       " 'gsce',\n",
       " 'crude',\n",
       " 'hdl',\n",
       " 'nail',\n",
       " 'empty',\n",
       " 'mobilise',\n",
       " 'outtake',\n",
       " 'disclosurescotland',\n",
       " 'hazardous',\n",
       " \"chris's\",\n",
       " 'contractually',\n",
       " 'genres',\n",
       " 'disclosures',\n",
       " 'dictate',\n",
       " 'secondtonone',\n",
       " 'nestle',\n",
       " \"engineer's\",\n",
       " 'negligence',\n",
       " 'aelodau',\n",
       " 'marketresearch',\n",
       " 'manson',\n",
       " 'broader',\n",
       " 'mathematician',\n",
       " 'gordon',\n",
       " 'checker',\n",
       " 'fireworks',\n",
       " 'susurface',\n",
       " 'resume',\n",
       " 'stratford',\n",
       " 'skillsambitious',\n",
       " 'sgiliau',\n",
       " 'upwards',\n",
       " 'everevolving',\n",
       " 'koonerpertemps',\n",
       " 'fazed',\n",
       " 'cutters',\n",
       " 'webservices',\n",
       " 'jigiau',\n",
       " 'committing',\n",
       " 'timehours',\n",
       " 'upturn',\n",
       " 'bedding',\n",
       " 'chwilio',\n",
       " 'fancy',\n",
       " 'regt',\n",
       " 'domination',\n",
       " 'resultsfocussed',\n",
       " 'introduces',\n",
       " 'bridgend',\n",
       " 'shortlist',\n",
       " 'pipefitting',\n",
       " 'bydd',\n",
       " 'spotchecks',\n",
       " 'coherent',\n",
       " 'prepaid',\n",
       " 'checklists',\n",
       " 'downloads',\n",
       " 'france',\n",
       " 'valueadd',\n",
       " 'serviceuser',\n",
       " 'institutes',\n",
       " 'sterlingmccall',\n",
       " 'compilation',\n",
       " 'commmercial',\n",
       " 'psychometric',\n",
       " 'fulltimemy',\n",
       " 'crosssite',\n",
       " 'booster',\n",
       " 'prescriptions',\n",
       " 'consumption',\n",
       " 'paxton',\n",
       " 'averaging',\n",
       " 'edk',\n",
       " 'spots',\n",
       " 'burton',\n",
       " 'outdoors',\n",
       " 'apmi',\n",
       " 'opportunityto',\n",
       " 'gamp',\n",
       " 'gyfrannu',\n",
       " 'pf',\n",
       " 'shipment',\n",
       " 'citrix',\n",
       " 'documentations',\n",
       " 'mpgj',\n",
       " 'carwest',\n",
       " 'assault',\n",
       " 'negated',\n",
       " 'toptier',\n",
       " 'bom',\n",
       " 'lounge',\n",
       " 'pendrill',\n",
       " 'roster',\n",
       " 'showcasing',\n",
       " 'broomfield',\n",
       " 'bp',\n",
       " 'exposed',\n",
       " 'harm',\n",
       " 'block',\n",
       " 'territorymanager',\n",
       " 'liquids',\n",
       " 'unresolved',\n",
       " 'rejects',\n",
       " 'pp',\n",
       " 'omega',\n",
       " 'ordered',\n",
       " 'volt',\n",
       " 'gymru',\n",
       " 'acknowledging',\n",
       " 'databus',\n",
       " \"upp's\",\n",
       " 'calmly',\n",
       " 'samplingward',\n",
       " 'motortradejobs',\n",
       " 'sequence',\n",
       " 'archived',\n",
       " 'practicably',\n",
       " 'segmented',\n",
       " 'sevices',\n",
       " 'complemented',\n",
       " 'waking',\n",
       " 'lamps',\n",
       " 'unwell',\n",
       " 'ptt',\n",
       " 'upheld',\n",
       " 'truro',\n",
       " 'signoffs',\n",
       " 'thin',\n",
       " 'failed',\n",
       " 'relevantexperience',\n",
       " 'aspnetsoftwaredeveloperamigoloans',\n",
       " 'bobl',\n",
       " 'stop',\n",
       " 'evans',\n",
       " 'studier',\n",
       " 'porter',\n",
       " 'milstd',\n",
       " 'ash',\n",
       " 'dmwhwallacehind',\n",
       " \"i'n\",\n",
       " 'hopping',\n",
       " 'pvc',\n",
       " 'orrock',\n",
       " 'observed',\n",
       " 'islington',\n",
       " 'gds',\n",
       " 'validating',\n",
       " 'crac',\n",
       " 'ssl',\n",
       " 'ukas',\n",
       " 'catheterization',\n",
       " 'warmers',\n",
       " 'langley',\n",
       " 'payne',\n",
       " 'fifteen',\n",
       " 'lr',\n",
       " 'reaching',\n",
       " 'shortterm',\n",
       " 'lates',\n",
       " 'ddyfynnwyd',\n",
       " 'reinvest',\n",
       " 'migration',\n",
       " 'nadine',\n",
       " 'specifics',\n",
       " 'composed',\n",
       " 'symbol',\n",
       " 'tables',\n",
       " 'colton',\n",
       " 'janette',\n",
       " 'nichola',\n",
       " 'deputyhomemanager',\n",
       " 'unlawful',\n",
       " 'encouragement',\n",
       " 'obesity',\n",
       " 'lower',\n",
       " 'roaming',\n",
       " 'maturity',\n",
       " 'bushings',\n",
       " 'concession',\n",
       " 'customerscontinual',\n",
       " 'clearable',\n",
       " 'approvals',\n",
       " 'bartender',\n",
       " 'jack',\n",
       " 'effects',\n",
       " 'diffuse',\n",
       " 'flagship',\n",
       " 'deputybranchmanagerfolkestone',\n",
       " 'hurst',\n",
       " 'trustbased',\n",
       " 'forces',\n",
       " 'mjeffreyscompassltd',\n",
       " 'setters',\n",
       " 'joy',\n",
       " 'fail',\n",
       " 'omantechnicalsalesglobalcompany',\n",
       " 'jtag',\n",
       " 'surreysalary',\n",
       " 'accessni',\n",
       " 'anical',\n",
       " 'healthcarewith',\n",
       " 'landlord',\n",
       " 'chp',\n",
       " 'responsibly',\n",
       " 'delahuntyrandstad',\n",
       " 'daniella',\n",
       " 'bolsover',\n",
       " 'boasting',\n",
       " 'harmonious',\n",
       " 'ta',\n",
       " 'eyre',\n",
       " 'pressures',\n",
       " 'plccrawley',\n",
       " \"consultant's\",\n",
       " 'cfa',\n",
       " 'cro',\n",
       " 'mana',\n",
       " 'deficient',\n",
       " 'rsquot',\n",
       " \"hunt's\",\n",
       " 'bill',\n",
       " 'welded',\n",
       " 'evaluated',\n",
       " 'mpgw',\n",
       " \"cd's\",\n",
       " 'originating',\n",
       " 'gyflawni',\n",
       " 'nightrgnrequiredatnasebycareandnursinghome',\n",
       " 'gosodiad',\n",
       " 'belong',\n",
       " 'projectmanaging',\n",
       " 'cancellation',\n",
       " 'preparationof',\n",
       " 'pvt',\n",
       " 'directs',\n",
       " 'lewistimerecruitment',\n",
       " 'financialadministratorandsupportfleetdept',\n",
       " 'converging',\n",
       " 'inclining',\n",
       " 'compete',\n",
       " 'purchased',\n",
       " 'omb',\n",
       " 'addon',\n",
       " 'enterpriserecruitment',\n",
       " 'mcgougan',\n",
       " 'socialising',\n",
       " 'messages',\n",
       " 'forex',\n",
       " 'databooks',\n",
       " 'rgnqualified',\n",
       " 'grievance',\n",
       " 'informatio',\n",
       " 'remediate',\n",
       " 'regionally',\n",
       " 'zone',\n",
       " 'baileynorthstaffs',\n",
       " 'guillotines',\n",
       " 'gwelliant',\n",
       " 'misra',\n",
       " 'theukandsouth',\n",
       " 'allocate',\n",
       " 'occassionaly',\n",
       " 'councils',\n",
       " 'governments',\n",
       " 'embed',\n",
       " 'thoughts',\n",
       " 'assembling',\n",
       " 'soil',\n",
       " 'ifss',\n",
       " 'coat',\n",
       " 'playing',\n",
       " 'insa',\n",
       " 'alectorecruit',\n",
       " 'debit',\n",
       " 'dialoguelettersadviser',\n",
       " 'resourcerkareplus',\n",
       " 'attire',\n",
       " 'christchurch',\n",
       " 'fiscal',\n",
       " 'encountered',\n",
       " 'disappointed',\n",
       " 'modelsim',\n",
       " 'dmm',\n",
       " 'contrologix',\n",
       " 'wearresistant',\n",
       " 'cass',\n",
       " 'swanage',\n",
       " 'mixes',\n",
       " 'medicalrecruitmentaapct',\n",
       " 'tandberg',\n",
       " 'carveout',\n",
       " 'unqualified',\n",
       " 'attercliffe',\n",
       " 'spg',\n",
       " 'autoclaves',\n",
       " 'serviceengineercommercialcateringlaundryequipmentnorthamptonshire',\n",
       " 'flm',\n",
       " 'lewisham',\n",
       " 'faultfind',\n",
       " 'reservoirdriven',\n",
       " 'uncappedsales',\n",
       " 'gloucs',\n",
       " 'habits',\n",
       " 'fyddwch',\n",
       " 'rolewe',\n",
       " 'pragmatic',\n",
       " 'slow',\n",
       " 'dvds',\n",
       " 'pull',\n",
       " 'accrued',\n",
       " 'destruction',\n",
       " 'exc',\n",
       " 'jacksonastburymarsden',\n",
       " 'bowling',\n",
       " 'crawfordablyresources',\n",
       " 'chubb',\n",
       " 'isl',\n",
       " 'relief',\n",
       " 'salesrepresentativeleadgenerator',\n",
       " 'clinet',\n",
       " 'welleducated',\n",
       " 'downtime',\n",
       " 'cefndir',\n",
       " 'fieldsalesexecutivederby',\n",
       " 'aptitudes',\n",
       " 'twickenham',\n",
       " 'password',\n",
       " 'motorsport',\n",
       " 'transparently',\n",
       " 'blackberry',\n",
       " 'smb',\n",
       " 'directive',\n",
       " 'fulfill',\n",
       " 'felicityapprenticesales',\n",
       " 'kcarbens',\n",
       " 'bond',\n",
       " 'newhall',\n",
       " 'riskunderstanding',\n",
       " 'tunbridge',\n",
       " 'gmo',\n",
       " 'mewn',\n",
       " 'fed',\n",
       " 'collar',\n",
       " 'practiceif',\n",
       " 'classen',\n",
       " 'dutton',\n",
       " 'sterling',\n",
       " 'schememinimum',\n",
       " 'shower',\n",
       " 'barriers',\n",
       " 'swadlincote',\n",
       " 'recover',\n",
       " 'eb',\n",
       " 'clubs',\n",
       " 'basisthe',\n",
       " 'agreeing',\n",
       " 'defect',\n",
       " 'caats',\n",
       " 'prisons',\n",
       " 'disclose',\n",
       " 'competitivesalary',\n",
       " 'nonspecific',\n",
       " 'parallel',\n",
       " 'inquisitive',\n",
       " 'residual',\n",
       " 'steering',\n",
       " 'equations',\n",
       " 'twg',\n",
       " 'datrys',\n",
       " 'loved',\n",
       " 'rosters',\n",
       " 'themed',\n",
       " 'laptopyour',\n",
       " 'quo',\n",
       " 'fights',\n",
       " 'sas',\n",
       " 'xpath',\n",
       " 'housework',\n",
       " 'underpinned',\n",
       " \"person's\",\n",
       " 'newbies',\n",
       " 'magazines',\n",
       " 'netherton',\n",
       " 'distressed',\n",
       " 'wholesaledepartment',\n",
       " 'allocating',\n",
       " 'aswel',\n",
       " 'portugal',\n",
       " 'machinesalesrepconstructionequipmentuncappedote',\n",
       " 'tangible',\n",
       " 'labview',\n",
       " 'experimentation',\n",
       " 'renown',\n",
       " 'matched',\n",
       " 'shokerpenguinrecruitment',\n",
       " 'mangotsfield',\n",
       " 'annotation',\n",
       " 'petersfield',\n",
       " 'targetorientated',\n",
       " 'estimations',\n",
       " 'toptable',\n",
       " 'notifications',\n",
       " 'manger',\n",
       " 'enterprising',\n",
       " 'photocopying',\n",
       " 'purposely',\n",
       " 'adoperation',\n",
       " 'autorefractors',\n",
       " 'savouries',\n",
       " 'mangers',\n",
       " 'irb',\n",
       " 'upkeep',\n",
       " 'hanner',\n",
       " 'collaborative',\n",
       " 'venous',\n",
       " 'convictions',\n",
       " 'elimination',\n",
       " 'trailers',\n",
       " 'relative',\n",
       " 'react',\n",
       " 'behaviors',\n",
       " 'rhwng',\n",
       " 'ce',\n",
       " 'businesslink',\n",
       " 'partnered',\n",
       " 'baker',\n",
       " 'dead',\n",
       " 'football',\n",
       " 'dewranceaaronwallis',\n",
       " 'fd',\n",
       " 'fellows',\n",
       " 'professor',\n",
       " 'particpate',\n",
       " 'standardised',\n",
       " 'customs',\n",
       " 'wonderful',\n",
       " 'evaluations',\n",
       " 'federation',\n",
       " 'faultfree',\n",
       " 'westmeath',\n",
       " 'grave',\n",
       " 'timber',\n",
       " 'carmobile',\n",
       " 'preventive',\n",
       " 'ddefnyddio',\n",
       " 'sutherland',\n",
       " 'pipefitter',\n",
       " 'communicators',\n",
       " 'wills',\n",
       " 'policyassess',\n",
       " 'lanecramlingtonnorthumberlandne',\n",
       " 'mindset',\n",
       " 'hymgynghorwyr',\n",
       " 'concisely',\n",
       " 'focusa',\n",
       " 'intricate',\n",
       " 'esk',\n",
       " 'vessel',\n",
       " 'industryinternational',\n",
       " 'propective',\n",
       " 'monetary',\n",
       " 'pair',\n",
       " 'stretched',\n",
       " 'benefitting',\n",
       " 'helpdesk',\n",
       " 'leinster',\n",
       " 'sleepovers',\n",
       " 'thedition',\n",
       " 'rg',\n",
       " 'pharmacists',\n",
       " 'radius',\n",
       " 'randstadcare',\n",
       " 'comanage',\n",
       " 'salesmanagerwithdigitaladvertisingexperience',\n",
       " 'cocn',\n",
       " 'sharedservice',\n",
       " 'owning',\n",
       " 'generallocation',\n",
       " 'racheal',\n",
       " 'responsibilitiesassess',\n",
       " 'interruption',\n",
       " 'fenland',\n",
       " 'farringdon',\n",
       " 'visibility',\n",
       " 'auditexecutive',\n",
       " 'timesto',\n",
       " 'aldershot',\n",
       " 'seat',\n",
       " 'simulators',\n",
       " 'solver',\n",
       " 'policymakers',\n",
       " 'lt',\n",
       " 'apacs',\n",
       " 'preassessment',\n",
       " 'fr',\n",
       " 'wwf',\n",
       " 'homeaddress',\n",
       " 'redditch',\n",
       " 'affordability',\n",
       " 'homec',\n",
       " 'glesurfredlinegroup',\n",
       " 'lodgings',\n",
       " 'clapham',\n",
       " 'appendage',\n",
       " 'ofeurope',\n",
       " 'highvolume',\n",
       " 'adeiladu',\n",
       " 'jedwardscitizenrecruitment',\n",
       " 'taxfree',\n",
       " 'meade',\n",
       " 'violent',\n",
       " 'hants',\n",
       " 'recharge',\n",
       " 'confer',\n",
       " 'patented',\n",
       " 'gaming',\n",
       " 'smoking',\n",
       " 'sportswearmulti',\n",
       " 'accustomed',\n",
       " 'unmatched',\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_fd = FreqDist(words) # compute term frequency for each unique word/type\n",
    "print('-'*40)\n",
    "print('Term frequencies:')\n",
    "print('-'*40)\n",
    "print(rm_fd.most_common()[9300:-1])\n",
    "print('-'*40)\n",
    "# get words with only 1 frequency \n",
    "lessFreqWords = set(rm_fd.hapaxes())\n",
    "print('-'*40)\n",
    "print('Less frequent words:')\n",
    "print('-'*40)\n",
    "lessFreqWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removewords(array,words):\n",
    "    \"\"\" removes the less frequent words from a list of tokens \n",
    "    \"\"\"\n",
    "    return [w for w in array if w not in words]\n",
    "# Remove less frequent words: \n",
    "tokenised_job_descriptions = [removewords(job,lessFreqWords) for job in tokenised_job_descriptions] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above the words with a term frequency of 1 was removed from the list of tokens because like stop words , as they only appear once, they hold no useful predicit capabilites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genertate a document frequency distribution \n",
    "words_2 = list(chain.from_iterable([set(job) for job in tokenised_job_descriptions]))\n",
    "doc_fd = FreqDist(words_2)  # compute document frequency for each unique word/type\n",
    "doc_fd_50=doc_fd.most_common(50)\n",
    "\n",
    "# remove top 50 words in document frequency distribution \n",
    "mostfreq= set([k for k, v in doc_fd_50])\n",
    "\n",
    "\n",
    "tokenised_job_descriptions = [removewords(job,mostfreq) for job in tokenised_job_descriptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving required outputs\n",
    "**FILES TO SAVE**\n",
    "- vocab.txt\n",
    "- jobs.txt \n",
    "- job_types.txt\n",
    "- webindxs.txt\n",
    "-job_titles.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveinfo(directory, array):\n",
    "    out_file = open(directory, 'w') # creates a txt file \n",
    "    for job in array:\n",
    "        try:\n",
    "           \n",
    "           \n",
    "            if directory == \"./jobs.txt\":\n",
    "                out_file.write(' '.join(job) + '\\n')\n",
    "                \n",
    "            else:\n",
    "                out_file.write(''.join(job) + '\\n')\n",
    "        except Exception:\n",
    "            out_file.write('INVALID'+'\\n')\n",
    "    out_file.close() # close the file\n",
    "\n",
    "# Save files: \n",
    "job_file = \"./jobs.txt\"\n",
    "jobtype_file = \"./job_types.txt\"\n",
    "webindxs_file = \"./webindxs.txt\"\n",
    "jobtitles_file=\"./jobtitles.txt\"\n",
    "\n",
    "saveinfo(job_file,tokenised_job_descriptions)\n",
    "saveinfo(jobtype_file,job_type)\n",
    "saveinfo(webindxs_file,job_indxs)\n",
    "saveinfo(jobtitles_file,job_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Vocab.txt file \n",
    "# generate vocab list:\n",
    "words = list(chain.from_iterable(tokenised_job_descriptions)) \n",
    "vocab = set(words)\n",
    "\n",
    "out_file = open(\"./vocab.txt\", 'w') # creates a txt file named './bbcNews_voc.txt', open in write mode\n",
    "vocab = list(vocab)\n",
    "vocab.sort()\n",
    "# sort the vocab list alphabetically and assign value according to its alphabetical order \n",
    "for ind in range(0, len(vocab)):\n",
    "    out_file.write(\"{}:{}\\n\".format(vocab[ind],ind)) # write each index and vocabulary word, note that index start from 0\n",
    "out_file.close() # close the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Overall a relatively comprehensive text pre-processing methodology was performed on the job description data to imporve the accuracy of any NLP model used on said data. The methodolgy included tokenization , stopword removal , Less and most frequent term removal and removal of short words, all of which aim to reduce the impact of unimportant / words with limited predictive capabilities so that words that give a better indication of the job type take up a larger proportion of the data. One common step that could also be performed would be lemmatization or stemming which aim to reduce tokens to thier root word, however for the purpose of our evaluations this step is not important.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Advprograming')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0df5ee365d35a626221b5001fbdb1e76763ab51facbf8a47e0f27e408b0d7b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
